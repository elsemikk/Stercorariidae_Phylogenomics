# Mapping to the reference genome

After trimming reads, we can map them to the reference genome. I am generating two datasets mapping to two different reference genomes of different phylogenetic distances. First, we are mapping sequencing reads from each sample to the reference genome of *Stercorarius parasiticus*, which we assembled into pseudochromosomes based on synteny with *Alca torda*. This genome is part of our ingroup, and so should have better mapping quality, but some analyses would be biased because each sample will have a different genetic distance to the reference. I am calling this dataset "c". Next, I will map to the *Alca torda* genome, which is more distant, but is equally distant to each of the ingroup samples. I am calling that dataset dataset "d". Each of my filenames after these steps is labelled either "c" or "d" depending on which reference it is using.  

### Overview
This section details how the trimmed sequencing reads were mapped to the *Stercorarius parasiticus* reference genome.  

### Required Input
This step requires the trimmed sequencing read data, which was generated in the previous step (`1.1c_read_trimming`), and a reference genome (from step `0.1`). These trimmed reads are not in the repository, as the file size is too large, but can be easily regenerated from the raw reads.  

### Output
The output is sorted, indexed alignment data in bam format ready for genotype calling.  

# Map with bowtie2

I am mapping the data using bowtie2 with the --very-sensitive setting, which should allow for mapping our slightly divergent (up to approximately 4.6% for the Alcid) genomes to the reference, without introducing too many mismappings. I tested several different settings with bowtie2 and with bwa, and selected bowtie2 --very-sensitive as it allowed for a higher mapping rate without elevating heterozygosity of the female Z chromosome (which should have no heterozygosity except for errors) - I found that the default settings with bwa allowed for a slightly higher mapping rate, but at the cost of elevating heterozygosity on the female Z, suggesting that mapping errors were being introduced.  

Before we can map our sequences, we must prepare the reference genome by indexing it for Bowtie2, if we have note done so already:  
```bash
time /home/0_PROGRAMS/bowtie2-2.4.4-linux-x86_64/bowtie2-build /home/0_GENOMES5/Stercorarius/0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa Stercorarius_parasiticus.ref #39m56.672s
time /home/0_PROGRAMS/samtools-1.14/samtools faidx /home/0_GENOMES5/Stercorarius/0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa #0m4.733s
```
`Stercorarius_parasiticus.ref`: this is a tag name for the build, it will be the prefix of the output files and you will give this name to bowtie later when you do the mapping step.  

**Timing**:Building took 29m11.639s (1 thread) and indexing took only 4 seconds.

# Map to the indexed reference sequence

In this step, we will loop through our samples and map them to the reference genome using bowtie2. If you only have a single sequencing run per sample, then this is quite simple. However, most of our samples were divided across multiple sequencing runs. Now, we could simply concatenate the raw sequencing data from all runs of a given sample and map it in one go. However, doing so would erase some valuable information pertaining to the origin of each read. The reason that this matters is that during a sequencing run, a single DNA fragment is amplified many times to form clusters which are then read by the machine's sensors. If the machine misinterprets a single cluster as two adjacent clusters, it will produce "optical duplicates" - that is, two different reads that are identical because they originated from the exact same fragment of DNA. Since these do not represent independant replicates drawn from the genome, they can bias SNP calling pipelines that assume each sequenced read at diploid locus is a random draw from either homologous chromosome. Luckily, if we know that two reads came from adjacent clusters of the same sequencing flow cell, the optical duplicates can be identified and removed to keep only one copy.  

For this to work, we need to supply some information to the mapper so that it known what sequencing run each read came from and can add this info into the .bam file. I am storing this info into a file that I will loop through to supply the necessary information to bowtie2 for each sample.  

This file has 6 tab-seperated columns.  
1) Sample name  
2) Unique ID for each run (I am naming with the convention `flowcell.lane.sample`)  
3) Library number (arbitrary, refers to samples that were prepped together in the lab)  
4) `Flowcell.lane.barcode`  
5) Platform (Illumina)  
6) Prefix used to identify the correct fastq files and name the output  

Some of this info may be in the .fastq file header. For example, we can read the first header line of our fastq files like this:  
```bash
ls *_R1*.fastq.gz | while read file ; do echo $file ; zcat $file | head -n 1 ; done #for fastq.gz
ls *_R1*.fastq | while read file ; do echo $file ; head -n 1 $file ; done #for fastq

```
For example, for one of my samples the header looks like this:  
```
@E00387:393:H7723CCX2:8:1101:25317:1116 2:N:0:46
```
This tells us that the read came from flowcell H7723CCX2 lane 8. I went through and collected this info from each file, where possible. Some of this info may be lacking in public data, such as from Genbank, to save file space.  

I saved this info into a text file that I can loop through:  

```bash
#First, make some folders in which to place our mappings
mkdir -p /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping #on the new server
cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping

mkdir -p /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/2_PROJECTS/Stercorarius/1_Data/1.3c_mapping #on main server
cd /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/2_PROJECTS/Stercorarius/1_Data/1.3c_mapping

#create the readgroups file
cat > readgroups #copy-paste the text below, press enter, and press ctrl-d to exit. Whatever you copy-pasted will be written to the file.
```
Here are the contents. The columns must be space-separated for my script to work:  
```
ANSK01 HWWLTDSX2.1.ANSK01 Lib-4 HWWLTDSX2.1.TAATGCGC+AGGCTATA Illumina ANSK01_S7_L001
ANSK7 H7723CCX2.8.ANSK7 Lib-2 H7723CCX2.8.46 ILLUMINA ANSK7_S46_L008
ANSK8 HWWLTDSX2.1.ANSK8 Lib-4 HWWLTDSX2.1.ATTCAGAA+GCCTCTAT Illumina ANSK8_S8_L001
CISK2 HWWLTDSX2.1.CISK2 Lib-4 HWWLTDSX2.1.CTGAAGCT+AGGCTATA Illumina CISK2_S6_L001
CISK_3 H7VVVCCX2.1.CISK_32 Lib-3 H7VVVCCX2.1.NTCCTCCT ILLUMINA CISK3_S1_L001 
CISK55 HWWLTDSX2.1.CISK55 Lib-4 HWWLTDSX2.1.GAATTCGT+AGGCTATA Illumina CISK55_S5_L001
GRSK_MKP1593 HWWLTDSX2.1.GRSK_MKP1593 Lib-4 HWWLTDSX2.1.ATTCAGAA+AGGCTATA Illumina GRSK_MKP1593_S4_L001
GRSK_MKP1592 HWNWMCCXY.1.GRSK_MKP1592 Lib-1 HWNWMCCXY.1.NACTGAGC+NAATCAGG ILLUMINA HI.4998.001.IDT_i7_18---IDT_i5_18.GRSK_MKP1592
GRSK_MKP1592 HYFKVCCXY.1.GRSK_MKP1592 Lib-1 HYFKVCCXY.1.NACTGAGC+NAATCAGG ILLUMINA HI.5011.004.IDT_i7_18---IDT_i5_18.GRSK_MKP1592
POJA_MKP1559 HWNWMCCXY.1.POJA_MKP1559 Lib-1 HWNWMCCXY.1.NCGTCATT+NAGACGTT ILLUMINA HI.4998.001.IDT_i7_30---IDT_i5_30.POJA_MKP1559
POJA_MKP1559 HYFKVCCXY.4.POJA_MKP1559 Lib-1 HYFKVCCXY.4.NCGTCATT+NAGACGTT ILLUMINA HI.5011.004.IDT_i7_30---IDT_i5_30.POJA_MKP1559
LTJA_MKP990 HWNWMCCXY.1.LTJA_MKP990 Lib-1 HWNWMCCXY.1.NTGTTGAC+NCCTCAGT ILLUMINA HI.4998.001.IDT_i7_54---IDT_i5_54.LTJA_MKP990
LTJA_MKP990 HYFKVCCXY.4.LTJA_MKP990 Lib-1 HYFKVCCXY.4.NTGTTGAC+NCCTCAGT ILLUMINA HI.5011.004.IDT_i7_54---IDT_i5_54.LTJA_MKP990
PAJA_B20730 HYFKVCCXY.4.PAJA_B20730 Lib-1 HYFKVCCXY.4.NGGTTGTT+NTGGTATG ILLUMINA HI.5011.004.IDT_i7_42---IDT_i5_42.PAJA_B20730
PAJA_B20730 HWNWMCCXY.1.PAJA_B20730 Lib-1 HWNWMCCXY.1.NGGTTGTT+NTGGTATG ILLUMINA HI.4998.001.IDT_i7_42---IDT_i5_42.PAJA_B20730
POJA_4 HWWLTDSX2.1.POJA_4 Lib-4 HWWLTDSX2.1.CTGAAGCT+GCCTCTAT Illumina POJA_4_S10_L001
POJA_IB2659 HWWLTDSX2.1.POJA_IB2659 Lib-4 HWWLTDSX2.1.GAATTCGT+GCCTCTAT Illumina POJA_IB2659_S9_L001
PAJA_USNM606730 FCC2J5BACXX.2.PAJA_USNM606730 Lib-5 FCC2J5BACXX.2.NA ILLUMINA SRR10019945
CHSK_MKP2451 H2HVJCCX2.3.CHSK_MKP2451 Lib-1 H2HVJCCX2.3.NGCATGAT+NAGCCTGA ILLUMINA HI.5080.003.IDT_i7_7---IDT_i5_7.CHSK_MKP2451
CHSK_MKP2451 H2HVJCCX2.4.CHSK_MKP2451 Lib-1 H2HVJCCX2.4.NGCATGAT+NAGCCTGA ILLUMINA HI.5080.004.IDT_i7_7---IDT_i5_7.CHSK_MKP2451
PAJA_USNM606730 FCC2J5BACXX.1.PAJA_USNM606730 Lib-5 FCC2J5BACXX.1.NA ILLUMINA SRR10019934
Fratercula_arctica NA.NA.Fratercula_arctica Lib-5 NA.NA.NA ILLUMINA ERR4669697
Alca_torda FCC4UDBACXX.1.Alca_torda Lib-5 FCC4UDBACXX.1.NA ILLUMINA SRR9853758
Alca_torda FCC4UDBACXX.8.Alca_torda Lib-5 FCC4UDBACXX.8.NA ILLUMINA SRR9853828
Alca_torda FCC4UDBACXX.5.Alca_torda Lib-5 FCC4UDBACXX.5.NA ILLUMINA SRR9853829
Alca_torda FCC4UDBACXX.2.Alca_torda Lib-5 FCC4UDBACXX.2.NA ILLUMINA SRR9853830
Alca_torda FCC4UDBACXX.7.Alca_torda Lib-5 FCC4UDBACXX.7.NA ILLUMINA SRR9853831
Uria_lomvia C2F25ACXX.NA.Uria_lomvia Lib-5 C2F25ACXX.4.NA ILLUMINA SRR5884877
Uria_lomvia NA.NA.Uria_lomvia Lib-5 NA.NA.NA ILLUMINA SRR5884878
Uria_lomvia NA.NA.Uria_lomvia Lib-5 NA.NA.NA ILLUMINA SRR5884875
```

In addition, we will need a list of samples to loop through. This file will be very useful later on to cycle through the samples when you need to run the same commands on all samples, without needing to write out the same command 6 (or more) times. It is similar to the above file, but only lists the sample names, not the sequencing file names.  

```bash
cat > samples.txt #copy-paste the text below, press enter, and press ctrl-d to exit. Whatever you copy-pasted will be written to the file.
```
```
ANSK01
ANSK8
CISK55
GRSK_MKP1593
POJA_4
POJA_IB2659
LTJA_MKP990
PAJA_B20730
POJA_MKP1559
CHSK_MKP2451
GRSK_MKP1592
CISK3
Fratercula_arctica
CISK2
Alca_torda
ANSK7
PAJA_USNM606730
Uria_lomvia

```

Note: we need a final "return" at the end of the last line (creating a new blank line at the end) otherwise it will skip the last sample as it will lack a "newline" character at the end of the line - so just press "enter" once after you have copy-pasted it into terminal to start a new line before finishing your file. Also make sure there are no spaces or tabs at the end of the lines.  

## Map all samples to the reference
In a preliminary run of this project, I tested various settings of Bowtie2; these can be found in Appendix A in the step 1.3d. I chose the `--very-sensitive` setting and also reduced the mismatch penalty (`--mp 5,1`) since I am mapping samples that are phylogenetically somewhat distant to the reference genome, and so we expect there to be many mismatches between the reference and the sequencing reads.    
We will feed the input `readgroups` file to `parallel` which will then parse the columns and place the required info to the mapping command which will run each sample in parallel. (tutorial on using parallel [here](https://opensource.com/article/18/5/gnu-parallel))  

We will pipe the output of bowtie2 directly into samtools sort and then fixmate, and then pipe the output of fixmate directly into samtools sort again, since we have no use for the unsorted, giant intermediate files. (there is a nice samtools tutorial [here](http://quinlanlab.org/tutorials/samtools/samtools.html))  

Once each sequencing run has been mapped, we can merge the runs of the same samples so that we only have one bam file per sample. we will directly pipe this merged file into samtools markdup to identify and mark the optical duplicates. Finally, we simply index the bam file and it is ready for downstream use! Note that we always convert the sam file to bam file format since sam files take up much more space (for example, a 63 Gb sam file can be stored as a 14-18 Gb bam file!)  

```bash
#set up environment
#cd /home/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping #on node
#cd /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/2_PROJECTS/Stercorarius/1_Data/1.3c_mapping #on main server
cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping #on new server

mkdir -p mapping_logs

#get readgroups file (see above)

#run the mapper and pipe output to fixmate
#Fixmate adds information on insert size and mate pair coordinates. note fixmate normally requires bam file to be sorted by read name, but bwa outputs the sam file essentially sorted by name already with mates one after the other. 
#before we can merge our sequencing runs, we must also sort each run by genomic position. 
cat readgroups | parallel --jobs 18 --colsep ' ' 'time /home/0_PROGRAMS/bowtie2-2.4.4-linux-x86_64/bowtie2 --end-to-end --very-sensitive --no-unal --threads 1 -q --phred33 --time --mp 5,1 -x ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref -1 ../1.1c_read_trimming/fltrd_adptrlss{6}_R1.fastq.gz -2 ../1.1c_read_trimming/fltrd_adptrlss{6}_R2.fastq.gz --rg-id {2} --rg SM:{1} --rg LB:{3} --rg PU:{4} --rg PL:{5} 2> mapping_logs/{6}.PAJAbowtie.log | /home/0_PROGRAMS/samtools-1.14/samtools sort -n -O sam | time /home/0_PROGRAMS/samtools-1.14/samtools fixmate -@ 1 -m - - | /home/0_PROGRAMS/samtools-1.14/samtools sort -O BAM > {6}.{1}_sorted.bam'

#on main server
#cat readgroups | parallel --jobs 18 --colsep ' ' 'time /home/0_PROGRAMS/bowtie2-2.4.4-linux-x86_64/bowtie2 --end-to-end --very-sensitive --no-unal --threads 4 -q --phred33 --time --mp 5,1 -x ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref -1 /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/1_PROCESSED_READS/3_TRIMMED/Stercorariidae/fltrd_adptrlss{6}_R1.fastq.gz -2 /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/1_PROCESSED_READS/3_TRIMMED/Stercorariidae/fltrd_adptrlss{6}_R2.fastq.gz --rg-id {2} --rg SM:{1} --rg LB:{3} --rg PU:{4} --rg PL:{5} 2> mapping_logs/{6}.PAJAbowtie.log | /home/0_PROGRAMS/samtools-1.14/samtools sort -n -O sam | time /home/0_PROGRAMS/samtools-1.14/samtools fixmate -@ 1 -m - - | /home/0_PROGRAMS/samtools-1.14/samtools sort -O BAM > {6}_sorted.bam'

#Now we can merge the results of each sequencing run for each sample (do not merge different samples together though! Each bam should be seperated into seperate files per SAMPLE, but we are merging different RUNS of the SAME sample). This is done based on naming each run with the name of the sample.
#right after merging, we can mark duplicates. We don't need any intermediate file for anything, so jut pipe directly to markdup.
mkdir -p merged
cat samples.txt | parallel --jobs 15 'time /home/0_PROGRAMS/samtools-1.14/samtools merge - *{1}*_sorted.bam -u | time /home/0_PROGRAMS/samtools-1.14/samtools markdup -@ 4 - merged/{1}.PAJAbowtie.marked.bam'

#note that we MARKED duplicates but we did not remove them - they are still there. You can remove them with the -r flag.

#index the bam with samtools for downstream programs that require an index
cat samples.txt | parallel 'time /home/0_PROGRAMS/samtools-1.14/samtools index merged/{1}.*.marked.bam'

#Now we have a bam file ready to use! BE AWARE: there has been no filtering. You will have to implement some filtering before calling genotypes etc.

#To save space, go ahead and delete any of the unmerged bam files. I see no reason you would need them for anything you could not used the merged files for, assuming the merging all went smoothly. Worst case scenario, you can remake them.
#rm ./*_sorted.bam #careful
```
bowtie2 settings:
* -`-rg-id`: Set the read group ID to <text>. This causes the SAM @RG header line to be printed, with <text> as the value associated with the ID: tag. It also causes the RG:Z: extra field to be attached to each SAM output record, with value set to <text>.
* `--rg` Add <text> (usually of the form TAG:VAL, e.g. SM:Pool1) as a field on the @RG header line. Note: in order for the @RG line to appear, --rg-id must also be specified. This is because the ID tag is required by the SAM Spec. Specify --rg multiple times to set multiple fields. See the SAM Spec for details about what fields are legal.
* `--no-unal`: Suppress SAM records for reads that failed to align.
* `--mp MX,MN` Sets the maximum (MX) and minimum (MN) mismatch penalties, both integers. A number less than or equal to MX and greater than or equal to MN is subtracted from the alignment score for each position where a read character aligns to a reference character, the characters do not match, and neither is an N. If --ignore-quals is specified, the number subtracted quals MX. Otherwise, the number subtracted is MN + floor( (MX-MN)(MIN(Q, 40.0)/40.0) ) where Q is the Phred quality value. Default: MX = 6, MN = 2.
samtools view:
* `-S`: the input is a SAM file (no longer required as this can be automatically detected)
* `-b`: the output will be BAM format
* `-@`: number of threads to use for BAM compression
* `-h`: include the header in the output
* `-q 5`: Skip alignments with MAPQ smaller than the specified number. This is to avoid multimapped sequences and mappings with low confidence. You could filter by 0 or 1, or 5 or 10, there is a discussion [here](https://www.biostars.org/p/101533/).
* `-f2`: only include properly paired reads
fixmate
* `-m`: "Add ms (mate score) tags. These are used by markdup to select the best reads to keep."
* -@: number of threads to use for BAM compression
samtools merge
* First list the output ("-" for piping), then the inputs
* `-u`: uncompressed output. Since we are just piping to the next command, no point wasting time compressing in between.
samtools markdup
* opposite of merge: first list the input, then the output

**Timing**: first batch of Stercorariids took 334m (888m) to 516m (1343m) depending on file size, using 4 threads each

Now we have a bam file for each sample ready to call SNPs or use as input for analysis!

# Evaluate results

Now that we have mapped our samples, we can do some visualization and calculate some statistics to evaluate the mapping results.

First, I will get some general stats from samtools (manual for these commands [here](http://www.htslib.org/doc/samtools-1.6.html)).  
Then I will look at some more details with [Qualimap](http://qualimap.bioinfo.cipf.es/doc_html/analysis.html).  

Note, you don't have to run all of these QC programs, they are redundant, but I find it fun to compare.

I am running all my samples in parallel at the same time which is described [here](https://www.gettinggeneticsdone.com/2014/03/visualize-coverage-exome-targeted-ngs-bedtools.html)  
(I am NOT running Qualimap in parallel because that would take too much memory and crash. One at a time.)  

```bash
cd /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/2_PROJECTS/Stercorarius/1_Data/1.3c_mapping #on main server
mkdir -p QC_reports

cat samples.txt | parallel 'time /home/0_PROGRAMS/samtools-1.14/samtools flagstat merged/{1}.PAJAbowtie.marked.bam > QC_reports/flagstats_{1}.txt'
cat samples.txt | parallel 'time /home/0_PROGRAMS/samtools-1.14/samtools idxstats merged/{1}.PAJAbowtie.marked.bam > QC_reports/idxstats_{1}.txt'
cat samples.txt | parallel 'time /home/0_PROGRAMS/samtools-1.14/samtools stats merged/{1}.PAJAbowtie.marked.bam > QC_reports/samstats_{1}.txt'

conda activate java8
cat samples.txt | while read line ; do time /home/0_PROGRAMS/qualimap_v2.2.1/qualimap bamqc -bam merged/"$line".PAJAbowtie.marked.bam -c -ip -nt 24 --java-mem-size=4G -outdir QC_reports/"$line"_qualimap ; done
#for line in Uria_lomvia ; do time /home/0_PROGRAMS/qualimap_v2.2.1/qualimap bamqc -bam merged/"$line".PAJAbowtie.marked.bam -c -ip -nt 24 --java-mem-size=8G -outdir QC_reports/"$line"_qualimap ; done #4G was not enough memory for Uria, which has the most data, so I had to increase the --java-mem-size parameter.

#conda activate fastqc
#multiqc QC_reports -n mapping_qc -o QC_reports -f

#get average depths of each sample
cat samples.txt | while read sample ; do echo "$sample" ; time /home/0_PROGRAMS/samtools-1.14/samtools depth merged/"$sample".*.marked.bam | awk '{sum+=$3; sumsq+=$3*$3} END { print "Average = ",sum/NR; print "Stdev = ",sqrt(sumsq/NR - (sum/NR)**2)}' ; done
```
qualimap:
* `-c`:Paint chromosome limits inside charts
* `-ip`: collect information on reads overlapping between paired end mates.
* `-nt`: number of threads to use
* `--java-mem-size=4G`: increases memory allowance, it was crashing after around half way done otherwise.

**Results**:  
* flagstats should show 100% of reads are mapped and properly paired (since that was our filter), and 50% are read 1 and 50% are read 2. It is not informative except to indicate if there was a problem with our filter. Everything looks good there  
* idxstats reports contig names, contig length, and number of mapped reads per contig. I would like to use this to identify the sex of the samples - see below.
* samtools stats gives you the info from flagstats and much more: insert size, avg quality, #bases mapped, and distributions for many attributes such as coverage, insert size, and quality. This is more useful. Looks fine. Most relevant results are tabulated below. All libraries show similar insert sizes so that's good.

This is the output of the average depth calculation:  
```
ANSK01
Average =  11.1523
Stdev =  44.2956

real	12m16.683s
user	16m22.652s
sys	0m22.776s
ANSK8
Average =  11.7215
Stdev =  47.0208

real	13m18.555s
user	17m38.736s
sys	0m23.148s
CISK55
Average =  12.402
Stdev =  57.3365

real	13m43.634s
user	18m12.368s
sys	0m22.748s
GRSK_MKP1593
Average =  9.22516
Stdev =  48.7704

real	11m37.537s
user	15m16.324s
sys	0m21.924s
POJA_4
Average =  12.3208
Stdev =  36.777

real	14m33.029s
user	19m4.356s
sys	0m23.404s
POJA_IB2659
Average =  12.0019
Stdev =  51.4246

real	13m46.511s
user	18m6.072s
sys	0m22.600s
LTJA_MKP990
Average =  16.2047
Stdev =  76.7069

real	12m59.205s
user	18m7.796s
sys	0m23.508s
PAJA_B20730
Average =  15.4689
Stdev =  79.1158

real	13m17.868s
user	18m8.404s
sys	0m22.680s
POJA_MKP1559
Average =  13.4846
Stdev =  67.3219

real	11m28.123s
user	16m8.548s
sys	0m21.916s
CHSK_MKP2451
Average =  9.94329
Stdev =  54.4107

real	11m44.529s
user	15m27.720s
sys	0m22.056s

GRSK_MKP1592
Average =  12.7192
Stdev =  60.5149

real	12m45.888s
user	17m8.208s
sys	0m23.128s
CISK3
Average =  9.6808
Stdev =  66.4968

real	11m35.395s
user	15m15.716s
sys	0m22.028s
Fratercula_arctica
Average =  8.28149
Stdev =  13.902

real	11m21.641s
user	14m44.864s
sys	0m21.616s

CISK2
Average =  12.9447
Stdev =  72.3056

real	13m1.218s
user	17m23.828s
sys	0m22.572s

Alca_torda
Average =  13.3416
Stdev =  7.76177

real	12m55.954s
user	18m51.412s
sys	0m23.996s

ANSK7
Average =  12.0617
Stdev =  42.9131

real	12m50.446s
user	17m16.684s
sys	0m23.648s

PAJA_USNM606730
Average =  15.7035
Stdev =  6.31023

real	13m31.245s
user	18m43.160s
sys	0m24.384s

Uria_lomvia
Average =  46.9325
Stdev =  30.8404

real	17m17.132s
user	29m33.432s
sys	0m32.452s
```
I accidentally ran that command again, I am recording the results to see how consistent the timing are:  
```
ANSK01
Average =  11.1523
Stdev =  44.2956

real	12m21.062s
user	16m40.600s
sys	0m28.660s

ANSK8
Average =  11.7215
Stdev =  47.0208

real	13m24.980s
user	17m55.820s
sys	0m29.072s

CISK55
Average =  12.402
Stdev =  57.3365

real	14m34.860s
user	19m27.368s
sys	0m29.588s

GRSK_MKP1593
Average =  9.22516
Stdev =  48.7704

real	12m13.908s
user	16m2.536s
sys	0m26.376s

POJA_4
Average =  12.3208
Stdev =  36.777

real	14m16.656s
user	18m57.648s
sys	0m28.584s

POJA_IB2659
Average =  12.0019
Stdev =  51.4246

real	13m29.547s
user	18m0.164s
sys	0m28.144s

LTJA_MKP990
Average =  16.2047
Stdev =  76.7069

real	13m49.635s
user	19m11.280s
sys	0m29.148s

PAJA_B20730
Average =  15.4689
Stdev =  79.1158

real	12m25.585s
user	17m12.352s
sys	0m24.476s

POJA_MKP1559
Average =  13.4846
Stdev =  67.3219

real	12m16.131s
user	16m34.704s
sys	0m23.460s

CHSK_MKP2451
Average =  9.94329
Stdev =  54.4107

real	11m46.145s
user	15m34.700s
sys	0m22.936s

GRSK_MKP1592
Average =  12.7192
Stdev =  60.5149

real	13m18.599s
user	17m46.260s
sys	0m24.748s

CISK3
Average =  9.6808
Stdev =  66.4968

real	12m13.315s
user	15m55.788s
sys	0m22.416s

Fratercula_arctica
Average =  8.28149
Stdev =  13.902

real	10m37.479s
user	14m2.588s
sys	0m24.284s

CISK2
Average =  12.9447
Stdev =  72.3056

real	12m33.096s
user	16m50.032s
sys	0m22.036s

Alca_torda
Average =  13.3416
Stdev =  7.76177

real	12m48.251s
user	18m26.608s
sys	0m25.288s

ANSK7
Average =  12.0617
Stdev =  42.9131

real	16m23.180s
user	21m36.828s
sys	0m31.700s

PAJA_USNM606730
Average =  15.7035
Stdev =  6.31023

real	15m48.863s
user	22m8.896s
sys	0m30.220s

Uria_lomvia
Average =  46.9325
Stdev =  30.8404

real	17m54.947s
user	31m2.404s
sys	0m42.248s
```
