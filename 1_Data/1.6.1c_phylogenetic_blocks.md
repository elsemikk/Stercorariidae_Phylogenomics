## Overview
This page describes how to generate phased haplotype blocks for downstream phylogenetic analysis with Starbeast3. In this procedure, we phase a VCF file of variants, generate chromosome-length alignments, and then break these alignments into short blocks distributed throughout the genome.  

## Required Input
As input, we need a VCF file of variants, and bam files of aligned sequencing reads for each sample.  

## Output
The output is a phased VCF file and phased sequence alignments. This dataset is used for StarBeast3 and Phylonet.  

# Select candidate blocks to phase

First, we start out with our unphased VCF file containing trusted genotypes, with both variant and invariant sites, filtered carefully to avoid bias against SNPs in any particular lineage. I am going to generate 5 kb blocks to determine which ones have enough data (i.e., less than 20% missing data). I don't want to waste time phasing genotypes that will be discarded, because this step is computationally intensive.  

Our first step is to just decide which blocks to phase. Phasing is very computationally intensive, so we cannot phase the entire dataset (well, we could, but it would take weeks). In the end, blocks with a lot of missing data will not be useful to me, so I will only phase the blocks that pass a minimum threshold of usefulness. I will keep 5-kb blocks with no more than 20% missing data in them. This keeps only 53,200 5-kb blocks, which is feasible to phase.  

First, we need a text file listing all the chromosomes/scaffolds to phase so that we can loop through them:  
```bash
cat > chromosomes
```
```
chr1
chr2
chr3
chr4
chr5
chr6
chr7
chr8
chr9
chr10
chr11
chr12
chr13
chr14
chr15
chr16
chr17
chr18
chr19
chr20
chr21
chr22
chr23
chr24
chr25
```

Next, we generate (unphased) chromosome-length sequences for each sample, combine them into multifasta sequence alignments, and split them into 5-kb blocks. We will filter to remove blocks with more than 20% missing data to retain our set of data that will be most useful to phase.  
```bash
#try a different filter
mkdir -p /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
cd  /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
mkdir -p filtered_haplotypes

tagname=PAJAbowtie

#generate consensus sequence, incorporating heterozygous sites as as IUPAC ambiguity codes.
parallel --colsep " " 'time /home/0_PROGRAMS/samtools-1.14/samtools faidx ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa {2}: | /home/0_PROGRAMS/bcftools-1.14/bcftools consensus --sample {1} --haplotype I --absent N --missing N --include '\''TYPE="snp" || TYPE="ref"'\'' ../1.5c_genotyping/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.auto.vcf.gz > filtered_haplotypes/{2}.{1}.diploid.'$tagname'.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia ::: chr1 chr2 chr3 chr4 chr5 chr6 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chr23 chr24 chr25 #39m15.221s

#replace the headers with sample names so that you can tell which came from which when you combine the files together later
#put the sample name in the fasta header
time parallel 'sed -i "s/>.*$/>{1}/g" filtered_haplotypes/{2}.{1}.diploid.'$tagname'.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia ::: chr1 chr2 chr3 chr4 chr5 chr6 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chr23 chr24 chr25

#combine fastas
#Combine all samples together
#make a copy in which the fasta entries have a single line per sequence, not multiline fasta
time cat chromosomes | while read scaffold ; do cat filtered_haplotypes/"$scaffold".*."$tagname".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > filtered_haplotypes/"$scaffold".fasta ; done

#split alignments into 5-kb chunks
conda activate basic
cd filtered_haplotypes #the script assumes the data is in the working directory
cat ../chromosomes | parallel time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb {1}.fasta blocks 5000 0.2
ls blocks | wc -l #count how many blocks were made
#53,200

#make a file listing the names of each block that has less than 20% missing data
ls blocks | sed 's/.nex//g; s/_/ /g' | awk '{ print $1,":",$2,"-",$3 }' OFS= > filtered_blocks.txt
```

Now we have a list of acceptable blocks, and we will phase them.  

# Phasing

Each sample has two copies of each autosomal locus, and the two copies can have different evolutionary histories. We need to disentangle the two haplotypes in order to reliably construct the tree. I am using Shapeit since it can take advantage of the information contained by the raw sequencing reads - since we have small sample sizes, phasing would otherwise be unreliable.  

To run shapeit, we need an input bamlist file:  
```bash
cat > bamlist.template
```
This file has three columns: 1) sample name 2) absolute path to bam file 3) chromosome of interest  
```
LTJA_MKP990 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/LTJA_MKP990.PAJAbowtie.marked.bam
PAJA_B20730 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/PAJA_B20730.PAJAbowtie.marked.bam
PAJA_USNM606730 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/PAJA_USNM606730.PAJAbowtie.marked.bam
POJA_MKP1559 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/POJA_MKP1559.PAJAbowtie.marked.bam
POJA_4 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/POJA_4.PAJAbowtie.marked.bam
POJA_IB2659 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/POJA_IB2659.PAJAbowtie.marked.bam
GRSK_MKP1592 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/GRSK_MKP1592.PAJAbowtie.marked.bam
GRSK_MKP1593 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/GRSK_MKP1593.PAJAbowtie.marked.bam
CISK_3 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/CISK3.PAJAbowtie.marked.bam
CISK55 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/CISK55.PAJAbowtie.marked.bam
CISK2 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/CISK2.PAJAbowtie.marked.bam
CHSK_MKP2451 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/CHSK_MKP2451.PAJAbowtie.marked.bam
ANSK7 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/ANSK7.PAJAbowtie.marked.bam
ANSK01 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/ANSK01.PAJAbowtie.marked.bam
ANSK8 /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/ANSK8.PAJAbowtie.marked.bam
Alca_torda /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/Alca_torda.PAJAbowtie.marked.bam
Uria_lomvia /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.3c_mapping/merged/Uria_lomvia.PAJAbowtie.marked.bam
```
Now we run shapeit. We need to be careful to undo imputing missing data, which is likely to be very inaccurate for this dataset and could introduce severe biases that would make downstream results unreliable.  
```bash
cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks

#First, extract snps from our region of interest from the vcf
mkdir -p phasing
cat filtered_haplotypes/filtered_blocks.txt | parallel '/home/0_PROGRAMS/bcftools-1.14/bcftools view -r {1} ../1.5c_genotyping/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.auto.vcf.gz -O z > phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz ; time /home/0_PROGRAMS/bcftools-1.14/bcftools index phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz' #took 1 second

#now, extract phase informative reads in this region
#first we have ta make a bamlist file
cat filtered_haplotypes/filtered_blocks.txt | parallel time 'sed "s/$/ {1}/g" bamlist.template | sed "s/:.*$//g" > phasing/{1}.bamlist' #less than a second
#then we can extract the PIRs
cat filtered_haplotypes/filtered_blocks.txt | parallel time /home/0_PROGRAMS/extractPIRs.v1.r68.x86_64/extractPIRs --bam phasing/{1}.bamlist --vcf phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz --out phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.PIRsList --base-quality 20 --read-quality 20 #took 1-7s per region

#finally, phase the vcf
cat filtered_haplotypes/filtered_blocks.txt | parallel time /home/0_PROGRAMS/shapeit.v2.904.3.10.0-693.11.6.el7.x86_64/bin/shapeit -assemble --input-vcf phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz --input-pir phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.PIRsList -O phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased --force #less than a second per region

#and convert the output back to VCF format
mkdir -p phased
cat filtered_haplotypes/filtered_blocks.txt | parallel time /home/0_PROGRAMS/shapeit.v2.904.3.10.0-693.11.6.el7.x86_64/bin/shapeit -convert --input-haps phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased --output-vcf phased/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf

#compress and index the vcf
cat filtered_haplotypes/filtered_blocks.txt | parallel 'time bgzip phased/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf'
cat filtered_haplotypes/filtered_blocks.txt | parallel 'time /home/0_PROGRAMS/bcftools-1.14/bcftools index phased/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf.gz'


#combine the SNPs back together with the invariants
#first extract the invariants
cat filtered_haplotypes/filtered_blocks.txt | parallel '/home/0_PROGRAMS/bcftools-1.14/bcftools view -r {1} ../../1_Data/1.5c_genotyping/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.auto.vcf.gz -O z > phasing/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.{1}.vcf.gz ; time /home/0_PROGRAMS/bcftools-1.14/bcftools index phasing/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.{1}.vcf.gz'
#then combine them with the variants
cat filtered_haplotypes/filtered_blocks.txt | parallel 'time /home/0_PROGRAMS/bcftools-1.14/bcftools concat --allow-overlaps phasing/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.{1}.vcf.gz phased/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf.gz -O z > phased/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{1}.shapeit.phased.vcf.gz' #takes a couple mins
#index the vcf file
cat filtered_haplotypes/filtered_blocks.txt | parallel 'time /home/0_PROGRAMS/bcftools-1.14/bcftools index phased/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{1}.shapeit.phased.vcf.gz' #takes less than a minute

```

Now we have a VCF file, but we need to be aware that all the missing data at the SNP sites has been imputed - I do not want that! I will have to replace it with missing data downstream.  

Now we will generate the haplotype sequences for our samples.  
```bash
cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
mkdir -p haplotypes
#generate haplotype 1
parallel --colsep " " 'time /home/0_PROGRAMS/samtools-1.14/samtools faidx ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa {2} | /home/0_PROGRAMS/bcftools-1.14/bcftools consensus --sample {1} --haplotype 1 --absent N --missing N phased/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{2}.shapeit.phased.vcf.gz > haplotypes/{2}.{1}.1.PAJAbowtie.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt

#generate haplotype 2
parallel --colsep " " 'time /home/0_PROGRAMS/samtools-1.14/samtools faidx ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa {2} | /home/0_PROGRAMS/bcftools-1.14/bcftools consensus --sample {1} --haplotype 2 --absent N --missing N phased/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{2}.shapeit.phased.vcf.gz > haplotypes/{2}.{1}.2.PAJAbowtie.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt

```

# Undo genotype imputation  
We are not quite done! Will still have to take out the imputed genotypes. I will do this with bedtools:  
1) make a bed file listing all the snp sites that have missing data for a given sample  
2) use bedtools to mask these sites in the fasta files.  
Remember:  
* bed files are *zero-based* for the start position. Meaning, if you want to mask the 10th nucleotide, you need to call it "9" in the bed start site  
* bed files are *one-based* for the end position, Meaning, if you want to mask the 10th nucleotide, you need to call it "9" in the bed end site  
So, this bed entry would mask just the tenth nucleotide: `chromosome1 9 10`  

```bash
#generate a bed file listing all the positions where a sample has a missing genotype
#this command views the VCF file for one particular sample - now all the sites either have 0% or 100% missing data. Exclude the sites with less than 50% missing data (so, exclude all the sites with a genotype call for that sample) and then use awk to turn that VCF file of missing sites into a bed file listing all of the missing sites for that sample. Remember to subtract one from the start position to match the BED zero-based system!
parallel /home/0_PROGRAMS/bcftools-1.14/bcftools view --samples {1} phasing/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{2}.vcf.gz '|' /home/0_PROGRAMS/bcftools-1.14/bcftools view --exclude \''F_MISSING<0.5'\' '|' awk \''$0 !~ /^#/ {print $1":",$2-1,$2}'\' '>' phasing/{2}.{1}.PAJAbowtie.merged.mask.bed ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt
#make bed files tab-delimited
parallel 'sed -i "s/ /\t/g" phasing/{2}.{1}.PAJAbowtie.merged.mask.bed' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt

#mask the fasta files by replacing these sites with N's
#first the first haplotype
mkdir -p masked_haplotypes
parallel 'time /home/0_PROGRAMS/bedtools maskfasta -fi haplotypes/{2}.{1}.1.PAJAbowtie.fa -bed phasing/{2}.{1}.PAJAbowtie.merged.mask.bed -fo masked_haplotypes/{2}.{1}.1.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt
#then the second haplotype
parallel 'time /home/0_PROGRAMS/bedtools maskfasta -fi haplotypes/{2}.{1}.2.PAJAbowtie.fa -bed phasing/{2}.{1}.PAJAbowtie.merged.mask.bed -fo masked_haplotypes/{2}.{1}.2.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt

#put the sample name in the fasta header
parallel 'sed -i "s/>.*$/>{1}.1/g" masked_haplotypes/{2}.{1}.1.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt
parallel 'sed -i "s/>.*$/>{1}.2/g" masked_haplotypes/{2}.{1}.2.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes/filtered_blocks.txt

#Combine all samples together
mkdir -p aligned
#cat chromosomes | parallel 'cat haplotypes/{1}.*.'$tagname'.lowconfmasked.fa > haplotypes/{1}.fa'
#make a copy in which the fasta entries have a single line per sequence, not multiline fasta
time cat filtered_haplotypes/filtered_blocks.txt | while read scaffold ; do cat masked_haplotypes/"$scaffold".*.PAJAbowtie.masked.fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > aligned/"$scaffold".fasta ; done #16m3.865s (6m35.168s) #1631m46.360s (578m17.165s) on new server!

```

# Calculate missing data per block
The last thing that I will do is to calculate the missingness for each sample. We have several thousand blocks, but it is computationally not feasible to analyze that entire dataset with Starbeast. We might select the best loci based on the amount of missing data.  

```bash
cat > samples.txt
```
```
LTJA_MKP990
PAJA_B20730
POJA_MKP1559
POJA_4
POJA_IB2659
GRSK_MKP1592
GRSK_MKP1593
CISK2
CISK55
CISK_3
CHSK_MKP2451
ANSK01
ANSK8
ANSK7
PAJA_USNM606730
Alca_torda
Fratercula_arctica
Uria_lomvia
```
```bash
cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks

#make folder to hold results
mkdir -p missingness
#for each sample, for each locus, count how many "N" or "n" are in the sequence. If there are gap characters, you should count those too.
time cat samples.txt | while read sample ; do echo "$sample" ; parallel '/home/0_PROGRAMS/seqkit grep -p '$sample'.1 aligned/{1}.fasta | grep -v ">" | tr -cd 'nN' | wc -c >> missingness/{1}.missingness' :::: filtered_haplotypes/filtered_blocks.txt ; done

#find the max amount of missing data in any Stercorariid for each block. Note I am not counting the Alcids.
cat filtered_haplotypes/filtered_blocks.txt | while read block ; do head -n 15 missingness/"$block".missingness | sort -n -r | head -n 1 >> missingness/maxmissing.txt ; done
paste filtered_haplotypes/filtered_blocks.txt missingness/maxmissing.txt > missingness/missingness.txt

#list sites with the max missingness less than 1 kb
awk '$2 <= 1000' missingness/missingness.txt | awk '$2 > 0' > missingness/passed.txt
#9899 blocks remain

awk '$2 <= 350' missingness/missingness.txt | awk '$2 > 0' > missingness/strictpassed.txt
#107 blocks remain
#note that the minimum distance between blocks in 10 kb.
```

Now we have a set of 9899 blocks where no Stercorariid is missing more than 1 kb, or 107 blocks where no Stercorariid is missing more than 350 bp (i.e., 7%). Note that none of the 107 blocks are adjacent to each other, so I will be treating them as "unlinked". It is possible that some on the same chromosome are in some degree of genetic linkage, and we do not have any linkage maps to inform us, but since they have at least 5000 bp of space between them (i.e., 5 kb windows 10 kb apart), they are at least unlikely to be very tightly linked.  


# Appendix: repeat for chrZ  
Here, I am repeating the process for chrZ. This data will *not* be used for Starbeast3. Note that many of our samples are females, which are hemizygous for chrZ, so phasing into two haplotypes does not make sense biologically for those samples. In addition, our filters were too strict to allow enough data to pass on chrZ - if we wanted to analyze chrZ with this pipeline, we would need to use more relaxed genotype filters with this dataset. It turned out that the only regions that passed our filters were in the region of the Z where homologous W chromosome sequences also map.  
```bash
#try a different filter
mkdir -p /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
cd  /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
mkdir -p filtered_haplotypes_chrZ

tagname=PAJAbowtie

#generate consensus sequence, incorporating heterozygous sites as as IUPAC ambiguity codes.
parallel --colsep " " 'time /home/0_PROGRAMS/samtools-1.14/samtools faidx ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa {2}: | /home/0_PROGRAMS/bcftools-1.14/bcftools consensus --sample {1} --haplotype I --absent N --missing N --include '\''TYPE="snp" || TYPE="ref"'\'' ../1.5c_genotyping/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.chr_Z.vcf.gz > filtered_haplotypes_chrZ/{2}.{1}.diploid.'$tagname'.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia ::: chrZ #6m17.192s

#replace the headers with sample names so that you can tell which came from which when you combine the files together later
#put the sample name in the fasta header
time parallel 'sed -i "s/>.*$/>{1}/g" filtered_haplotypes_chrZ/{2}.{1}.diploid.'$tagname'.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia ::: chrZ #0m15.235s

#combine fastas
#Combine all samples together
#make a copy in which the fasta entries have a single line per sequence, not multiline fasta
cat filtered_haplotypes_chrZ/chrZ.*."$tagname".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > filtered_haplotypes_chrZ/chrZ.fasta

conda activate basic
cd filtered_haplotypes_chrZ #the script assumes the data is in the working directory
time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb chrZ.fasta blocks 5000 0.2
ls blocks | wc -l #count how many blocks were made
#197
ls blocks | sed 's/.nex//g; s/_/ /g' | awk '{ print $1,":",$2,"-",$3 }' OFS= > chrZ_filtered_blocks.txt


cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
#First, extract snps from our region of interest from the vcf
mkdir -p phasing_chrZ
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel '/home/0_PROGRAMS/bcftools-1.14/bcftools view -r {1} ../1.5c_genotyping/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.chr_Z.vcf.gz -O z > phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz ; time /home/0_PROGRAMS/bcftools-1.14/bcftools index phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz' #took 1 second

#now, extract phase informative reads in this region
#first we have ta make a bamlist file
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel time 'sed "s/$/ {1}/g" bamlist.template | sed "s/:.*$//g" > phasing_chrZ/{1}.bamlist' #less than a second
#then we can extract the PIRs
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel time /home/0_PROGRAMS/extractPIRs.v1.r68.x86_64/extractPIRs --bam phasing_chrZ/{1}.bamlist --vcf phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz --out phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.PIRsList --base-quality 20 --read-quality 20 #took 1-7s per region

#finally, phase the vcf
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel time /home/0_PROGRAMS/shapeit.v2.904.3.10.0-693.11.6.el7.x86_64/bin/shapeit -assemble --input-vcf phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.vcf.gz --input-pir phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.PIRsList -O phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased --force #less than a second per region

#and convert the output back to VCF format
mkdir -p phased_chrZ
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel time /home/0_PROGRAMS/shapeit.v2.904.3.10.0-693.11.6.el7.x86_64/bin/shapeit -convert --input-haps phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased --output-vcf phased_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf

#compress and index the vcf
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel 'time bgzip phased_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf'
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel 'time /home/0_PROGRAMS/bcftools-1.14/bcftools index phased_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf.gz'

#combine the SNPs back together with the invariants
#first extract the invariants
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel '/home/0_PROGRAMS/bcftools-1.14/bcftools view -r {1} ../../1_Data/1.5c_genotyping/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.chr_Z.vcf.gz -O z > phasing_chrZ/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.{1}.vcf.gz ; time /home/0_PROGRAMS/bcftools-1.14/bcftools index phasing_chrZ/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.{1}.vcf.gz'
#then combine them with the variants
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel 'time /home/0_PROGRAMS/bcftools-1.14/bcftools concat --allow-overlaps phasing_chrZ/Stercorarius.PAJAbowtie.merged.invariant.for_pixy.{1}.vcf.gz phased_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{1}.shapeit.phased.vcf.gz -O z > phased_chrZ/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{1}.shapeit.phased.vcf.gz' #takes a couple mins
#index the vcf file
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | parallel 'time /home/0_PROGRAMS/bcftools-1.14/bcftools index phased_chrZ/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{1}.shapeit.phased.vcf.gz' #takes less than a minute

cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.1c_phylogenetic_blocks
mkdir -p haplotypes_chrZ
#generate haplotype 1
parallel --colsep " " 'time /home/0_PROGRAMS/samtools-1.14/samtools faidx ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa {2} | /home/0_PROGRAMS/bcftools-1.14/bcftools consensus --sample {1} --haplotype 1 --absent N --missing N phased_chrZ/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{2}.shapeit.phased.vcf.gz > haplotypes_chrZ/{2}.{1}.1.PAJAbowtie.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt
#generate haplotype 2
parallel --colsep " " 'time /home/0_PROGRAMS/samtools-1.14/samtools faidx ../../0_Reference_genome/0_reference/Stercorarius_parasiticus.ref.fa {2} | /home/0_PROGRAMS/bcftools-1.14/bcftools consensus --sample {1} --haplotype 2 --absent N --missing N phased_chrZ/Stercorarius.PAJAbowtie.merged.allsites.for_pixy.{2}.shapeit.phased.vcf.gz > haplotypes_chrZ/{2}.{1}.2.PAJAbowtie.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt


parallel /home/0_PROGRAMS/bcftools-1.14/bcftools view --samples {1} phasing_chrZ/Stercorarius.PAJAbowtie.merged.filteredSNPs.for_pixy.{2}.vcf.gz '|' /home/0_PROGRAMS/bcftools-1.14/bcftools view --exclude \''F_MISSING<0.5'\' '|' awk \''$0 !~ /^#/ {print $1":",$2-1,$2}'\' '>' phasing_chrZ/{2}.{1}.PAJAbowtie.merged.mask.bed ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt
#make bed files tab-delimited
parallel 'sed -i "s/ /\t/g" phasing_chrZ/{2}.{1}.PAJAbowtie.merged.mask.bed' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt

#mask the fasta files by replacing these sites with N's
#first the first haplotype
mkdir -p masked_haplotypes_chrZ
parallel 'time /home/0_PROGRAMS/bedtools maskfasta -fi haplotypes_chrZ/{2}.{1}.1.PAJAbowtie.fa -bed phasing_chrZ/{2}.{1}.PAJAbowtie.merged.mask.bed -fo masked_haplotypes_chrZ/{2}.{1}.1.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt
#then the second haplotype
parallel 'time /home/0_PROGRAMS/bedtools maskfasta -fi haplotypes_chrZ/{2}.{1}.2.PAJAbowtie.fa -bed phasing_chrZ/{2}.{1}.PAJAbowtie.merged.mask.bed -fo masked_haplotypes_chrZ/{2}.{1}.2.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt

#put the sample name in the fasta header
parallel 'sed -i "s/>.*$/>{1}.1/g" masked_haplotypes_chrZ/{2}.{1}.1.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt
parallel 'sed -i "s/>.*$/>{1}.2/g" masked_haplotypes_chrZ/{2}.{1}.2.PAJAbowtie.masked.fa' ::: LTJA_MKP990 PAJA_B20730 PAJA_USNM606730 POJA_MKP1559 POJA_4 POJA_IB2659 GRSK_MKP1592 GRSK_MKP1593 CISK2 CISK55 CISK_3 CHSK_MKP2451 ANSK7 ANSK01 ANSK8 Alca_torda Fratercula_arctica Uria_lomvia :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt

#Combine all samples together
mkdir -p aligned_chrZ
#cat chromosomes | parallel 'cat haplotypes_chrZ/{1}.*.'$tagname'.lowconfmasked.fa > haplotypes_chrZ/{1}.fa'
#make a copy in which the fasta entries have a single line per sequence, not multiline fasta
time cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | while read scaffold ; do cat masked_haplotypes_chrZ/"$scaffold".*.PAJAbowtie.masked.fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > aligned_chrZ/"$scaffold".fasta ; done #0m2.251s

#make folder to hold results
mkdir -p missingness_chrZ
#for each sample, for each locus, count how many "N" or "n" are in the sequence. If there are gap characters, you should count those too.
time cat samples.txt | while read sample ; do echo "$sample" ; parallel '/home/0_PROGRAMS/seqkit grep -p '$sample'.1 aligned_chrZ/{1}.fasta | grep -v ">" | tr -cd 'nN' | wc -c >> missingness_chrZ/{1}.missingness' :::: filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt ; done

#find the max amount of missing data in any Stercorariid for each block. Note I am not counting the Alcids.
cat filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt | while read block ; do head -n 15 missingness_chrZ/"$block".missingness | sort -n -r | head -n 1 >> missingness_chrZ/maxmissing.txt ; done
paste filtered_haplotypes_chrZ/chrZ_filtered_blocks.txt missingness_chrZ/maxmissing.txt > missingness_chrZ/missingness.txt

#list sites with the max missingness less than 1 kb
awk '$2 <= 1000' missingness_chrZ/missingness.txt | awk '$2 > 0' > missingness_chrZ/passed.txt
#33 blocks remain

awk '$2 <= 350' missingness_chrZ/missingness.txt | awk '$2 > 0' > missingness_chrZ/strictpassed.txt
#0 blocks remain
```

