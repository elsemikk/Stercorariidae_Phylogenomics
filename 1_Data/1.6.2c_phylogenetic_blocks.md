### Overview
This section details how to extract a "genome sequence" from the mapped, resequenced samples and divide the genome into blocks for use in downstream analyses. These blocks are based on genotype likelihoods within the framework of angsd. These blocks will be unphased.  

### Required Input
This step requires the mapped sequencing data, which was generated in the previous mapping step `1.3c_mapping.md`.  

### Output  
The output is a large number of sequence alignments for blocks throughout the genome, each containing all your samples. These can be used for phylogeny building or other analyses such as calculating genetic distances. This dataset is used for Astral-III and for the D3 test (including intermediate estimates of genetic distances between samples)  

# Step 1: Get chromosome fastas  
For some next analyses, we will need fasta sequences aligned for all samples. We can use angsd to convert the bam file alignments into chromosome-length fasta files for each scaffold of our genome.  

First, set up a folder with a list of samples to analyze.  
```bash
mkdir -p /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks
cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks
cd /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/2_PROJECTS/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks

cat > samples.txt
```
```
LTJA_MKP990
PAJA_B20730
PAJA_USNM606730
POJA_MKP1559
POJA_4
POJA_IB2659
GRSK_MKP1592
GRSK_MKP1593
CISK2
CISK55
CISK3
CHSK_MKP2451
ANSK7
ANSK01
ANSK8
Alca_torda
Fratercula_arctica
Uria_lomvia
```

Also get a list of chromosomes to loop through, to make a separate fasta file for each chromosome/scaffold.  
```bash
#get list of scaffolds/chromosomes
#These are listed, for example, in the idxstats output from any of the bam files
cat > scaff_names
```
```
chr1
chr2
chr3
chr4
chr5
chr6
chr7
chr8
chr9
chr10
chr11
chr12
chr13
chr14
chr15
chr16
chr17
chr18
chr19
chr20
chr21
chr22
chr23
chr24
chr25
chrZ
```

Then, give these to angsd. There are a few options for `-dofasta`. I initially chose 3 because it accounts for the mapping and base qualities to choose the best nucleotide at each position. I am also filtering for min base call and mapping quality of 20. However, I am concerned that including mapping quality in the choice of base will result in a bias against derived alleles (more specifically, against alleles that differ from the parasiticus reference genome), as these will have a mismatch that will lower mapping quality.  
```bash
cat samples.txt | parallel cat scaff_names '|' while read scaffold ';' do time /home/0_PROGRAMS/angsd/angsd -dofasta 3 -minMapQ 20 -minQ 20 -r \$scaffold: -i ../../1_Data/1.3c_mapping/merged/{1}.PAJAbowtie.marked.bam -out {1}_\$scaffold ';' echo {1}" is done" ';' done

#unzip the fastas
cat scaff_names | parallel gunzip -k *_{1}.fa.gz
#replace the headers with sample names so that you can tell which came from which when you combine the files together later
cat samples.txt | while read sample ; do cat scaff_names | while read scaffold ; do sed -i "s/^>.*$/>$sample/" "$sample"_"$scaffold".fa ; done ; done

```

Now we have scaffold sequences for each sample, we should combine them into a multifasta for each scaffold.
```bash
time cat scaff_names | while read scaffold ; do cat *_"$scaffold".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > "$scaffold".fa ; done

#took 3m17.764s
```
Simple! Now we have a fasta file of all samples.

I am making some other datasets to ensure that results are robust to choices of filters:  
```bash
#Repeat with more stringent settings
mkdir -p strict
cd strict
cat ../samples.txt | parallel time cat ../scaff_names '|' while read scaffold ';' do time /home/0_PROGRAMS/angsd/angsd -dofasta 3 -minMapQ 20 -minQ 20 -r \$scaffold: -i ../../../1_Data/1.3c_mapping/merged/{1}.PAJAbowtie.marked.bam -out {1}_\$scaffold -remove_bads 1 -only_proper_pairs 1 -uniqueOnly 1 -doCounts 1 -setMinDepth 3 ';' done #96m9.809s for the last (Uria lomvia) to finish
#unzip the fastas
cat ../scaff_names | parallel gunzip -k *_{1}.fa.gz
#replace the headers with sample names so that you can tell which came from which when you combine the files together later
cat ../samples.txt | while read sample ; do cat ../scaff_names | while read scaffold ; do sed -i "s/^>.*$/>$sample/" "$sample"_"$scaffold".fa ; done ; done
#combine fastas
time cat ../scaff_names | while read scaffold ; do cat *_"$scaffold".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > "$scaffold".fa ; done

#downstream analyses of this dataset cannot tolerate N's - I need to change them into gaps
#replace the Ns with "-" so they dont get incorporated into distance measures (important!)
time cat ../scaff_names | while read scaffold ; do sed 's/N/-/g' "$scaffold".fa > "$scaffold".noN.fa ; done
#Note that N's in sample names will also be converted: ANSK is now A-SK.



#less stringent MQ filters (MQ>15, dofasta2)
mkdir -p strict2
cd strict2
cat ../samples.txt | parallel cat ../scaff_names '|' while read scaffold ';' do time /home/0_PROGRAMS/angsd/angsd -dofasta 2 -minMapQ 15 -minQ 20 -r \$scaffold: -i ../../../1_Data/1.3c_mapping/merged/{1}.PAJAbowtie.marked.bam -out {1}_\$scaffold -remove_bads 1 -only_proper_pairs 1 -uniqueOnly 1 -doCounts 1 -setMinDepth 3 ';' done
#unzip the fastas
cat ../scaff_names | parallel gunzip -k *_{1}.fa.gz
#replace the headers with sample names so that you can tell which came from which when you combine the files together later
cat ../samples.txt | while read sample ; do cat ../scaff_names | while read scaffold ; do sed -i "s/^>.*$/>$sample/" "$sample"_"$scaffold".fa ; done ; done
#combine fastas
time cat ../scaff_names | while read scaffold ; do cat *_"$scaffold".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > "$scaffold".fa ; done
#downstream analyses of this dataset cannot tolerate N's - I need to change them into gaps
#replace the Ns with "-" so they dont get incorporated into distance measures (important!)
time cat ../scaff_names | while read scaffold ; do sed 's/N/-/g' "$scaffold".fa > "$scaffold".noN.fa ; done
#Note that N's in sample names will also be converted: ANSK is now A-SK.


#less stringent MQ filters (MQ>15, dofasta3)
mkdir -p strict3
cd strict3
cat ../samples.txt | parallel cat ../scaff_names '|' while read scaffold ';' do time /home/0_PROGRAMS/angsd/angsd -dofasta 3 -minMapQ 15 -minQ 20 -r \$scaffold: -i ../../../1_Data/1.3c_mapping/merged/{1}.PAJAbowtie.marked.bam -out {1}_\$scaffold -remove_bads 1 -only_proper_pairs 1 -uniqueOnly 1 -doCounts 1 -setMinDepth 3 ';' done
#unzip the fastas
cat ../scaff_names | parallel gunzip -k *_{1}.fa.gz
#replace the headers with sample names so that you can tell which came from which when you combine the files together later
cat ../samples.txt | while read sample ; do cat ../scaff_names | while read scaffold ; do sed -i "s/^>.*$/>$sample/" "$sample"_"$scaffold".fa ; done ; done
#combine fastas
time cat ../scaff_names | while read scaffold ; do cat *_"$scaffold".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > "$scaffold".fa ; done
#downstream analyses of this dataset cannot tolerate N's - I need to change them into gaps
#replace the Ns with "-" so they dont get incorporated into distance measures (important!)
time cat ../scaff_names | while read scaffold ; do sed 's/N/-/g' "$scaffold".fa > "$scaffold".noN.fa ; done
#Note that N's in sample names will also be converted: ANSK is now A-SK.


#more stringent MQ filters (MQ>20, dofasta2)
mkdir -p strict4
cd strict4
cat ../samples.txt | parallel cat ../scaff_names '|' while read scaffold ';' do time /home/0_PROGRAMS/angsd/angsd -dofasta 2 -minMapQ 20 -minQ 20 -r \$scaffold: -i ../../../1_Data/1.3c_mapping/merged/{1}.PAJAbowtie.marked.bam -out {1}_\$scaffold -remove_bads 1 -only_proper_pairs 1 -uniqueOnly 1 -doCounts 1 -setMinDepth 3 ';' done
#unzip the fastas
cat ../scaff_names | parallel gunzip -k *_{1}.fa.gz
#replace the headers with sample names so that you can tell which came from which when you combine the files together later
cat ../samples.txt | while read sample ; do cat ../scaff_names | while read scaffold ; do sed -i "s/^>.*$/>$sample/" "$sample"_"$scaffold".fa ; done ; done
#combine fastas
time cat ../scaff_names | while read scaffold ; do cat *_"$scaffold".fa |  awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}' | tr "\t" "\n" > "$scaffold".fa ; done
#downstream analyses of this dataset cannot tolerate N's - I need to change them into gaps
#replace the Ns with "-" so they dont get incorporated into distance measures (important!)
time cat ../scaff_names | while read scaffold ; do sed 's/N/-/g' "$scaffold".fa > "$scaffold".noN.fa ; done
#Note that N's in sample names will also be converted: ANSK is now A-SK.

```


# Step 2: Identify phylogenetic blocks  

Now, we can split each scaffold into blocks of a certain size. I am going with 5000 bp in length since linkage disequilibrium should remain strong within 5000 bp generally (of course, it is variable across the genome and it would be better to determine block size in terms of centimorgans. However, there is no genetic map for skuas at the moment.) See [Figure 3](https://www.researchgate.net/figure/Plot-of-linkage-disequilibrium-LD-r2-against-distance-between-SNPs-in-collared_fig4_261989789) of "Estimation of linkage disequilibrium and interspecific gene flow in Ficedula flycatchers by a newly developed 50k SNP array" for a curve of how linkage disequilibrium decays in *Ficedula* flycatchers. At 5 kb, LD looks around 0.09. A smaller block size would likely be better, as within 5 kb there is still a high chance for recombination to have occurred between SNPs, but below 5 kb there would be fewer SNPs and it would be difficult to reconstruct any gene trees. It is a tradeoff between retaining enough data for phylogenetics vs ensuring each block has a single topology. With 5 kb blocks, we only get around 20-30 parsimony informative sites per block, but this should be enough to make a small phylogeny.  

This script will split each scaffold into the specified block size (takes a few seconds per scaffold), and exclude blocks with too much missing data. It is quick. Note the fasta must have a single line for each entry, no multiline sequences!  

```bash
#this dataset is used for D3 and Astral-III (after downstream filtering)
cd /home/0_GENOMES1/0_RESEQUENCING_PROJECTS/2_PROJECTS/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks/strict
conda activate basic #has ruby installed
#create phylogenetic blocks (as explained in the Phylogenetic Blocks page of this repository). Takes up to 2m45 per scaffold.
cat ../scaff_names | parallel time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb {1}.noN.fa blocks 5000 0.2
ls blocks | wc -l #count how many blocks were made
#223915

#repeat for three other datasets, to investigate impact of choice of filters


cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks/strict2
conda activate basic
#create phylogenetic blocks (as explained in the Phylogenetic Blocks page of this repository). Takes up to 2m45 per scaffold.
cat ../scaff_names | parallel time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb {1}.noN.fa blocks 10000 0.05
ls blocks | wc -l #count how many blocks were made
cat ../scaff_names | parallel time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb {1}.noN.fa blocksmin20 5000 0.2
ls blocksmin20 | wc -l #count how many blocks were made

cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks/strict3
conda activate basic
cat ../scaff_names | parallel time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb {1}.noN.fa blocks 5000 0.2
ls blocks | wc -l #count how many blocks were made

cd /home/1_Else/0_GENOMES5/Stercorarius/1_Data/1.6.2c_phylogenetic_blocks/strict4
conda activate basic
cat ../scaff_names | parallel time ruby /home/0_PROGRAMS/mmatschiner/extract_blocks.rb {1}.noN.fa blocks 5000 0.2
ls blocks | wc -l #count how many blocks were made
#204365
```
* `blocks`: name of output directory that will contain the new blocks
* `5000`: block size length (bp)
* `0.5`: maximal fraction of missing data allowed within a block



Finally, we have blocks of fasta files, aligned for our species, that we can use to build phylogenies!  
