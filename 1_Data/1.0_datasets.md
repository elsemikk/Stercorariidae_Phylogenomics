### Overview
This section documents how the data was downloaded, and how sequencing quality was assessed. If this project were to be replicated, most of these steps would be skipped, as the data would be available from the SRA (rather than the sequencing facilities); I include it here for completeness.

### Required Input
This step requires the raw sequencing data, which will be available from the NCBI SRA.

### Output
The output is raw sequencing reads ready for quality trimming.

The data in this project is in 3 sources:
* 5 samples from the Royal Ontario Museum were sequenced at the Genome Quebec Innovation Centre on Hiseq X
* 2 samples from the Royal Ontario Museum were sequenced at the Centre for Applied Genomics on Hiseq X
* 7 samples from the Royal Ontario Museum were sequenced at the Centre for Applied Genomics on Novaseq S4 (Hiseq X was now phased out)
* 1 sample was obtained from Genbank that had already been sequenced for genome assembly, and which had publicly available data
* An outgroup species was selected which had already been sequenced for genome assembly, and which had publicly available data. The data for these samples were obtained from the SRA.


The sequences that we generated are stored on the server here:
```bash
#Here is where we will put the raw fastq.gz files:
mkdir -p /home/0_GENOMESrawDATA/HISEQX_RESEQUENCED/Stercorariidae/Raw_Genome_Data

#Here is where we will put sample IDs, QC data for the raw sequencing data, md5 checksums, sequencing lane indexes, etc
mkdir -p /home/0_GENOMESrawDATA/HISEQX_RESEQUENCED/Stercorariidae/Raw_Genome_Data_AssociatedFiles
```

# Genome Quebec Datasets

* CHSK_MKP2451, GRSK_MKP1592, LTJA_MKP990, PAJA_B20730, and POJA_MKP1559 were sequenced at the Genome Quebec Innovation Centre in Montreal, Quebec, Canada.
* The skuas and jaegers were each sequenced with two runs of paired-end Illumina reads, with each run labelled with "prefix" and "prefix2". These are PCR-free libraries. GRSK, POJA, PAJA, LTJA, and CHSK were sequenced together in the same lane.  

I downloaded the Genome Quebec dataset using Nanuq:
* Go to your completed project, select the HiSeq Read Sets tab, check the box(es) of the sample you wish to download, and click "Download Read Files". 
* Choose "Download Files from Selected Reads", "Compressed File", Fastq R1, and Fastq R2/R3, and then click "Download".  
It will probably be in a zipped file containing both read sets. You will have to unzip twice (zipped files within a zip file).  
OR: download from command line (simpler)

Upon completion of this project, the data will be available to download from the SRA.

Here is how I unzipped the Nanuq files:  
```bash
#To make life easier, we will set a variable $prefix to hold the name of our sequencing files so that we don't have to type it each time. 
#Your paired read files, once unzipped, should have the format of `"$prefix"_R1` and `"$prefix"_R2`. The other set of reads will be `"$prefix2"_R1` and `"$prefix2"_R2`.

#name the files you want to unzip
zipfile1="160787415" #name of the zipfile containing compressed reads
zipfile2="718794743" #name of your second file if there is a second run

#move the sequencing reads to your project folder
mkdir zipped_data
mv ~/Downloads/"$zipfile1".zip ./zipped_data
mv ~/Downloads/"$zipfile2".zip ./zipped_data

#unzip them into your zipped_data folder. The -d tells it where to place the output (into ./zipped_data)
unzip -d ./zipped_data ./"$zipfile1".zip 
unzip -d ./zipped_data ./"$zipfile2".zip 
#produces two .gz files per zipped file containing the forwards and reverse reads

#save some space by removing the original zip file
rm ./"$zipfile1".zip 
rm ./"$zipfile2".zip 
```

# TCAG Dataset

* CISK_32 was sequenced using a NEB Ultra II DNA library prep (PCR library, not PCR-free) at the Center for Applied Genomics in Toronto, Ontario, Canada. Note that a PCR library was used due to insufficient DNA concentration for the PCR-free library prep.
* ANSK7 was sequenced on Hiseq X alongside some songbirds and paleognath birds, with a PCR-free library prep at the Center for Applied Genomics.
* ANSK01, ANSK8, CISK2, CISK55, GRSK_MKP1593, POJA_4, and POJA_B2659 were sequenced on a Novaseq 6000 S4, with a PCR-free library prep at the Center for Applied Genomics. These samples sequenced after the others, after the first round of review, and so at this time the Hiseq X was no longer available.

```bash
cd /home/0_GENOMESrawDATA/HISEQX_RESEQUENCED/Stercorariidae/Raw_Genome_Data
time /home/0_PROGRAMS/tcag-client-1.4.2 download -p ONJ3UQT:/ #files are in ONJ3UQT/MIK19573.20220117/220114_A00481_0344_BHWWLTDSX2
#entered my user & password for TCAG 
#these files are now deleted from the tcag file system.
mv ONJ3UQT/MIK19573.20220117/220114_A00481_0344_BHWWLTDSX2/*fastq.gz .
mv ONJ3UQT/MIK19573.20220117/220114_A00481_0344_BHWWLTDSX2/*md5 ../Raw_Genome_Data_AssociatedFiles/Sequencefiles_checksums

```

# SRA datasets

To make a proper phylogeny, we also need an outgroup. The closest extant relatives to the Stercorariidae is likely Alcidae. There is some uncertainty about whether Stercorariidae is sister to Laridae, or Alcidae, or both, but in any case the difference in distance is likely small and the most recent evidence suggests that Alcidae is the sister of Stercorariidae. When I started this project, there were no genome assemblies or whole genome sequencing reads available for Laridae, but there were two for Alcidae. 

On SRA, there are several Alcid whole genome shotgun sequences available. I will use *Alca torda*, the same sample used as a reference genome. 

There were the following options available
* Fratercula arctica x 72: Hiseq 4000 sequenced to medium depth
* Uria lomvia: HiSeq 2500 sequenced to high depth for de novo assembly
* Alca torda: HiSeq 2000 sequenced to high depth for de novo assembly
* Alca torda #2: HiSeq 2000 sequenced to less than 3X depth so will not be as useful
* Uria aalge: HiSeq 2500 sequenced to high depth
* Ptychoramphus aleuticus: HiSeq 2000 sequenced to less than 3X depth so will not be as useful
* Cepphus grylle: HiSeq 2500 and Hiseq X sequenced to high depth

We can get the raw data off of NCBI. They are stored in the Short Read Archive (SRA), which we can access from the command line using a sra toolkit.

```bash
#I'm running on the Troglodytes node temporarily
cd /hhome/else/ncbi/public/sra
# Stercorarius parasiticus is split between 3 SRA entries. 
#get the sequencing data from NCBI 
#libraries with insert size 500: (Truseq, 150 bp)
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR10019934 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR10019934 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR10019945	
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR10019945 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
#library with insert size 2000: (Truseq, 50 bp) (will not use)
#~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9946748	
#~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9946748 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq

#I chose a Fratercula arctica sample with the most sequencing data (Truseq, 150 bp)
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch ERR4669697 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files ERR4669697 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq

#Uria lomvia has 3 Truseq libraries (I will not use the 4 mate-pair libraries) (Truseq, 100 bp)
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR5884875 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR5884875 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR5884877 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR5884877 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR5884878 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR5884878 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq

#Alca torda has 5 runs with 500 bp insert size, and a run with 2 kb insert size
#insert size 500 (Truseq, 100 bp)
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9853758 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9853758 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9853828	 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9853828	 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9853829 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9853829 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9853830	 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9853830	 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9853831	 
~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9853831	 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq

#Cepphus grylle
#~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch SRR9853786 
#~/tools/sratoolkit.2.9.6-1-ubuntu64/bin/fastq-dump -I --split-files SRR9853786 --defline-seq '@$sn[_$rn]/$ri' #convert from sra to fastq

#move them into their correct directory for storage
mkdir -p /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets
mv ./SRR10019934*fastq /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets
mv ./SRR10019945*fastq /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets
mv ./SRR9946748*fastq /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets
mv ./ERR4669697*fastq /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets

for accession in SRR9853829 SRR9853830 SRR9853831 SRR9853758 SRR9853828 SRR5884875 SRR5884877 SRR5884878 ; do mv ./"$accession"*fastq /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets ; done
for accession in SRR5884875 ; do mv ./"$accession"*fastq /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets ; done

#standardize names to match my other file conventions
cd /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets
rename 's/_1.fastq/_R1.fastq/g' ./*fastq*
rename 's/_2.fastq/_R2.fastq/g' ./*fastq*

#I deleted these raw fastq datasets to save space after I trimmed for adapters/quality; if I need the untrimmed data I can simply download it again
```

The ouput of prefetch should look like this:   
`
2019-10-15T20:16:53 prefetch.2.9.3: 1) Downloading 'SRR5884871'...  
2019-10-15T20:16:53 prefetch.2.9.3:  Downloading via fasp...  
SRR5884871                                      
2019-10-15T20:18:15 prefetch.2.9.3:  fasp download succeed  
2019-10-15T20:18:15 prefetch.2.9.3: 1) 'SRR5884871' was downloaded successfully  
2019-10-15T20:18:15 prefetch.2.9.3: 'SRR5884871' has 0 unresolved dependencies    
`
If there are errors, try again. Sometimes it just fails and will work the next time. SRR5884872 failed too many times so I stopped trying because I will not use it anyways (it is a 10kb insert nextera library, I only actually want the short insert data) 

For *Stercorarius parasiticus*: the SRA data from SRR9946748 is high quality in terms of Per base sequence quality scores but the reads are only 49 bp long so will be more difficult to map. I will discard it from further consideration. SRR10019934 and SRR10019945 are 150 bp and will be easier to map and more directly comparable to the data that we generated.

### alternate way to get SRA files
Here is an alternate way to download the data faster. First, make a list of the SRA files to download, so that we can do everything with one command:

```bash
cat > Urialomvia_SRR.txt #press enter, then ctrl-d to finish
```
```
SRR5884871
SRR5884872
SRR5884873
SRR5884874
SRR5884875
SRR5884876
SRR5884877
SRR5884878
```

Then get the data! Using the sra toolkit, it will automatically put the data into a folder located in `~/ncbi/public/sra` (if your setup is the same as mine).

```bash
cd ~/ncbi/public/sra

#download the SRA files.
cat Urialomvia_SRR.txt | while read line ; do /opt/tools/sratoolkit.2.9.6-1-ubuntu64/bin/prefetch -a '/hhome/else/.aspera/connect/bin/ascp|/hhome/else/.aspera/connect/etc/asperaweb_id_dsa.openssh' "$line" ; done

#convert sra file to fastq
conda activate sra
cat Urialomvia_SRR.txt | while read line ; do parallel-fastq-dump --sra-id "$line" --defline-seq '@$sn[_$rn]/$ri' --threads 24 --outdir ./ --split-files ; done

#redo any files that failed due to timeout.
parallel-fastq-dump --sra-id SRR5884872 --defline-seq '@$sn[_$rn]/$ri' --threads 24 --outdir ./ --split-files
parallel-fastq-dump --sra-id SRR5884877 --defline-seq '@$sn[_$rn]/$ri' --threads 24 --outdir ./ --split-files
parallel-fastq-dump --sra-id SRR5884878 --defline-seq '@$sn[_$rn]/$ri' --threads 24 --outdir ./ --split-files
```
**Timing**: It took 58 minutes to download everything. A few hours to convert to fastq.

*Notes*:  
* No matter what your working directory is, the files will end up in `~/ncbi/public/sra`
* Using Aspera connect is a bit more difficult to set up than the normal sra prefetch but it is MUCH faster. Before, *most* of my attempts at prefetch would time out and fail. Now they usually work. If they fail, just try again.
* I sometimes get a message like `err: timeout exhausted while waiting condition within process system module - failed SRR5884877`. Just try again until it works. Usually works the second time, sometimes needs a third try. **Parallel-fastq-dump** is HIGHLY recommended: It used to take many tries and much frustration just to get one large file converted to fastq because of this error when using regular fastq-dump, but parallel-fastq-dump is much faster and so has a lower chance to timeout.


# Assess data: check sequence quality
Before doing anything with our data, we need to make sure that it looks ok. We will do this with a popular program called [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/). I use it within a conda environment.

```bash
#activate your conda environment with fastqc installed
conda activate fastqc

#name the sequencing runs you are analyzing (the name of paired files should be "$prefix"_R1 and "$prefix"_R2)
prefix="Name_of_run"
#If you have a second set of reads from another run, name them too:
prefix2="Name_of_second_run"

#call the fastqc file from your tools folder. It should take less than 10 minutes per read set and will use 1 thread per readset.
fastqc -t 24 "$prefix"_R*.fastq.gz
fastqc -t 24 "$prefix2"_R*.fastq.gz

#alternatively, run FastQV on all files in the folder
#It should be quick with small files and take longer for the other files. It will use one thread per file and do them in parallel.
fastqc -t 24 SRR*.fastq

```
* -t 24: uses 24 threads, can change to the desired number. It seems will only use one thread per file.

To interpret the results take a look at the [tutorial here](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/3%20Analysis%20Modules/) and [here](https://dnacore.missouri.edu/PDF/FastQC_Manual.pdf).

After doing FastQC on all your reads, do multiqc to compare all results at once.

```bash
cd /home/0_GENOMES5/Stercorarius/1_Data/1.0_datasets
mkdir -p read_QC

#activate your conda environment with fastqc installed
conda activate fastqc #conda install -c bioconda fastqc

#call fastqc from conda. It should take less than 10 minutes per read set usually. I am running it all in parallel to save time. I am saving the output to another folder.

fastqc ./*fastq --threads 12 --outdir read_QC 

#Use multiQC to view summarized results. It should take less than a minute for directories with few files but can take much longer to search through big directories.
#visualize results
multiqc ./read_QC -o ./read_QC/ -n qc_report

```

Uria lomvia had a lot of data, so I chose just one run:

SRR5884878 Looks like a good run for Uria lomvia. Looking at the multiqc files, the sequences have lower quality than the skua sequences and are shorter (100bp rather than 150). SRR5884871, 73, 74, and 76 are the Nextera Mate Pair long insert libraries (and Nextera adapters are detected) This is a fairly different type of library than the skuas, and the paper indicated that a larger proportion of them were filtered out. Instead, the short insert libraries are what we would like to use for our outgroup since they are more similar to the skua data. These were sequenced on 3 lanes. The three runs are very similar, and the library content looks identical in terms of GC content. I randomly choose SRR5884878. It should give us comparable coverage too the best skua, and a bit higher. 

```bash
#move chosen files into target directory
mv ~/ncbi/public/sra/SRR5884878*.fastq ~/Stercorariidae/raw_data/Uria_lomvia

#remove all the other sra files to save space
cd ~/ncbi/public/sra/
rm ./*.sra

#remove the remaining fastq files to save space but be careful not to delete anything you did not mean to
```

Now we are ready to trim the sequencing files for downstream analyses.